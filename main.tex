\documentclass{beamer}
\usetheme{CambridgeUS}

\title{Assignment 7: Papoullis Text Book}
\author{Cherukupalli Sai Malini Mouktika}
\date{\today}
\logo{\large \LaTeX{}}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
 \usepackage{listings}
    \usepackage{color}                                            
    \usepackage{array}                                            
    \usepackage{longtable}                                        
    \usepackage{calc}                                            
    \usepackage{multirow}                                         
    \usepackage{hhline}                                          
    \usepackage{ifthen}   

\usepackage{multicolrule}


   
%table commands   
\def\inputGnumericTable{}

\usepackage[latin1]{inputenc}                                 
\usepackage{caption} 
\captionsetup[table]{skip=3pt}  

\renewcommand{\thefigure}{\arabic{table}}
\renewcommand{\thetable}{\arabic{table}}       


\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\newcommand{\graph}{\noindent \textbf{Graph: }}
\newcommand{\calc}{\noindent \textbf{Calculations: }}
\numberwithin{equation}{subsection}

\renewcommand{\thetable}{\theenumi}
\usepackage{amsmath}
\setbeamertemplate{caption}[numbered]{}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}

\begin{document}

\begin{frame}
    \titlepage 
\end{frame}

\logo{}

\begin{frame}{Outline}
    \tableofcontents
\end{frame}
\section{Question}
\begin{frame}{Question}
    \begin{block}{Example 8.9}
Suppose that $x = \theta + \textbf{v}$ is an $N (0, \sigma)$ random variable and $\theta$ is the value of 
an $N(\theta _{0} , \sigma _{0})$ random variable $\theta$ . Find the bayesian estimate $\hat{\theta}$ of $\theta$.
\end{block}
\end{frame}
\section{solution}
\begin{frame}{solution}
The density f(x | $\theta$) of x is $N(\theta , \sigma)$. We conclude that the function $f_{\theta}(\theta | x)$ is $N(\theta _{1} , \sigma _{1})$ where \\
\begin{align}
    \sigma_{1}^{2} &= \frac{\sigma ^{2}}{n} \times \frac{\sigma_{0}^{2}}{\sigma_{0}^{2} + \frac{\sigma ^{2}}{n}} \\
    \theta _{1} &= \frac{\sigma_{1}^{2}}{\sigma_{0}^{2}}\theta _{0} + \frac{n\sigma_{1}^{2}}{\sigma_{0}^{2}}\vec{x}
\end{align}
From this it follows that $E \lbrace\theta | x\rbrace = \theta _{1}$; in other words $\hat{\theta} = \theta _{1}$.
\end{frame}
\begin{frame}
The classical estimate of $\theta$ is the average $\Bar{x}$ of $x_{i}$. Furthermore, its prior 
estimate is the constant $\theta _{0}$. Hence $\hat{\theta}$ is the weighted average of the prior estimate $\theta _{0}$ and the classical estimate $\Bar{x}$. As n tends to $\infty$, $\sigma _{1} \rightarrow 0$ and $\frac{n\sigma_{1}^{2}}{\sigma_{0}^{2}} \rightarrow 1$; hence $\hat{\theta}$ tends to $\Bar{x}$. Thus, as the number of measurements increases, the bayesian estimate $\hat{\theta}$ approaches the classical estimate $\Bar{x}$; the effect of the prior becomes negligible.
\end{frame}

\end{document}
